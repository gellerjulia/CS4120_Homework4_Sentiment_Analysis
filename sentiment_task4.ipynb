{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4: Sentiment Analysis - Task 4\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: Julia Geller (4120) and Shae Marks (4120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Neural Networks (20 points)\n",
    "----\n",
    "\n",
    "Next, we'll train a feedforward neural net to work with this data. You'll train one neural net which takes the same input as your Logistic Regression model - a sparse vector representing documents as bags of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\J-Dog\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sentiment_utils as sutils\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# you can experiment with having some Dropout layers if you'd like to\n",
    "# this is not required\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# if you want to use this again\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants for the files we are using\n",
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "DEV_FILE = \"movie_reviews_dev.txt\"\n",
    "\n",
    "# load in your data and make sure you understand the format\n",
    "# Do not print out too much so as to impede readability of your notebook\n",
    "train_tups = sutils.generate_tuples_from_file(TRAIN_FILE)\n",
    "dev_tups = sutils.generate_tuples_from_file(DEV_FILE)\n",
    "\n",
    "# you may use either your sparse vectors or sklearn's CountVectorizer's sparse vectors\n",
    "# you will experiment with multinomial and binarized representations later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train and devlopment tuples into X and y\n",
    "X_train = train_tups[0]\n",
    "y_train = train_tups[1]\n",
    "\n",
    "X_dev = dev_tups[0]\n",
    "y_dev = dev_tups[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-tokenize reviews\n",
    "X_train_flat = [' '.join(row) for row in X_train]\n",
    "X_dev_flat = [' '.join(row) for row in X_dev]\n",
    "# get binary features using Sk-learns Count Vectorizer\n",
    "X_train_CV_binary, X_dev_CV_binary = sutils.featurize('CV', None, X_train_flat, X_dev_flat, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get multinomial features using Sk-learns Count Vectorizer\n",
    "X_train_multi, X_dev_CV_multi = sutils.featurize('CV', None, X_train_flat, X_dev_flat, binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               2259700   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2259801 (8.62 MB)\n",
      "Trainable params: 2259801 (8.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a feedforward neural network model\n",
    "# that takes a sparse BoW representation of the data as input\n",
    "# and makes a binary classification of positive/negative sentiment as output\n",
    "# you may use any number of hidden layers >= 1 and any number of units in each hidden layer (we recommend between 50-200)\n",
    "# you may use any activation function on the hidden layers \n",
    "# you should use a sigmoid activation function on the output layer\n",
    "# you should use binary cross-entropy as your loss function\n",
    "# sgd is an appropriate optimizer for this task\n",
    "# you should report accuracy as your metric\n",
    "# you may add Dropout layers if you'd like to\n",
    "\n",
    "# create/compile your model in this cell\n",
    "\n",
    "hidden_units = 100\n",
    "num_epochs = 10\n",
    "input_dim = len(X_train_CV_binary[0])\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# hidden layer \n",
    "model.add(Dense(units=hidden_units, activation='relu', input_dim=input_dim))\n",
    "# output layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# configure the learning process\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trainable parameters does your model have? 2,259,801"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 2s 19ms/step - loss: 0.6894 - accuracy: 0.5450\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.6675 - accuracy: 0.6956\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.6418 - accuracy: 0.7769\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.6131 - accuracy: 0.8231\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.5831 - accuracy: 0.8494\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.5536 - accuracy: 0.8644\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.5240 - accuracy: 0.8725\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.4952 - accuracy: 0.8813\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 1s 19ms/step - loss: 0.4676 - accuracy: 0.8856\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 1s 21ms/step - loss: 0.4413 - accuracy: 0.8919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b083a55940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train your model\n",
    "# Felix's computer takes about 2 sec for 3 epochs\n",
    "# reports an accuracy of 0.78 at that point using the sgd optimizer\n",
    "\n",
    "# Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, (<class 'list'> containing values of types {\"<class 'int'>\"})\n",
    "# indicates you should change a list into a numpy array\n",
    "\n",
    "model.fit(X_train_CV_binary, y_train, epochs=num_epochs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "# make a prediction on the dev set\n",
    "# then make a classification decision based on that prediction\n",
    "# predicting all examples takes < 1 sec on Felix's computer\n",
    "preds = model.predict(X_dev_CV_binary)\n",
    "preds = [1 if y >= 0.5 else 0 for y in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 10ms/step - loss: 0.5166 - accuracy: 0.7900\n",
      "loss: 0.5166181325912476 accuracy: 0.7900000214576721\n"
     ]
    }
   ],
   "source": [
    "# use the model.evaluate function to report the loss and accuracy on the dev set\n",
    "loss, acc = model.evaluate(X_dev_CV_binary, y_dev)\n",
    "print('loss:', loss, 'accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 of training data used\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6890 - accuracy: 0.5688\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.6780 - accuracy: 0.6687\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6664 - accuracy: 0.7063\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6558 - accuracy: 0.7625\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.6446 - accuracy: 0.8313\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "0.6461538461538462 0.4 0.4941176470588235 0.57\n",
      "0.2 of training data used\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6938 - accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6834 - accuracy: 0.5500\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6740 - accuracy: 0.5750\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6637 - accuracy: 0.6438\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6534 - accuracy: 0.7375\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "0.6923076923076923 0.42857142857142855 0.5294117647058824 0.6\n",
      "0.30000000000000004 of training data used\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 1s 10ms/step - loss: 0.6945 - accuracy: 0.5218\n",
      "Epoch 2/5\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6809 - accuracy: 0.5925\n",
      "Epoch 3/5\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6687 - accuracy: 0.6653\n",
      "Epoch 4/5\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.6559 - accuracy: 0.7838\n",
      "Epoch 5/5\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6436 - accuracy: 0.7401\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "0.7010309278350515 0.6476190476190476 0.6732673267326732 0.67\n",
      "0.4 of training data used\n",
      "Epoch 1/5\n",
      "20/20 [==============================] - 1s 14ms/step - loss: 0.6933 - accuracy: 0.5031\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6789 - accuracy: 0.6078\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6656 - accuracy: 0.6891\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6510 - accuracy: 0.7844\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6357 - accuracy: 0.7953\n",
      "7/7 [==============================] - 0s 5ms/step\n",
      "0.5952380952380952 0.9523809523809523 0.7326007326007327 0.635\n",
      "0.5 of training data used\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 1s 10ms/step - loss: 0.6904 - accuracy: 0.5625\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.6712 - accuracy: 0.6687\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.6514 - accuracy: 0.7700\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.6299 - accuracy: 0.8375\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.6084 - accuracy: 0.8687\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "0.676923076923077 0.8380952380952381 0.748936170212766 0.705\n",
      "0.6 of training data used\n",
      "Epoch 1/5\n",
      "30/30 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.5323\n",
      "Epoch 2/5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6735 - accuracy: 0.6750\n",
      "Epoch 3/5\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.6536 - accuracy: 0.7635\n",
      "Epoch 4/5\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.6315 - accuracy: 0.8104\n",
      "Epoch 5/5\n",
      "30/30 [==============================] - 0s 12ms/step - loss: 0.6077 - accuracy: 0.8417\n",
      "7/7 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\J-Dog\\23FALL\\CS4120_Homework4_Sentiment_Analysis\\sentiment_task4.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/J-Dog/23FALL/CS4120_Homework4_Sentiment_Analysis/sentiment_task4.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m train_feats \u001b[39m=\u001b[39m [(x, y) \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X_train_CV_binary, y_train) ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/J-Dog/23FALL/CS4120_Homework4_Sentiment_Analysis/sentiment_task4.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m dev_feats \u001b[39m=\u001b[39m [(x, y) \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X_dev_CV_binary, y_dev) ]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/J-Dog/23FALL/CS4120_Homework4_Sentiment_Analysis/sentiment_task4.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m sutils\u001b[39m.\u001b[39;49mcreate_training_graph(sutils\u001b[39m.\u001b[39;49mneural_net_metrics, train_feats, dev_feats, \u001b[39m'\u001b[39;49m\u001b[39mNeural Network\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mNeural_Network_CV_Binary_5Epochs_Graph.png\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m, \u001b[39m5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/J-Dog/23FALL/CS4120_Homework4_Sentiment_Analysis/sentiment_task4.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# # graph for Binary, Count Vectorizer, 10 epochs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/J-Dog/23FALL/CS4120_Homework4_Sentiment_Analysis/sentiment_task4.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# train_feats = [(x, y) for x,y in zip(X_train_CV_binary, y_train) ]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/J-Dog/23FALL/CS4120_Homework4_Sentiment_Analysis/sentiment_task4.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# dev_feats = [(x, y) for x,y in zip(X_dev_CV_binary, y_dev) ]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/J-Dog/23FALL/CS4120_Homework4_Sentiment_Analysis/sentiment_task4.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# dev_feats = [(x, y) for x,y in zip(X_dev_CV_binary, y_dev) ]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/J-Dog/23FALL/CS4120_Homework4_Sentiment_Analysis/sentiment_task4.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# sutils.create_training_graph(sutils.neural_net_metrics, train_feats, dev_feats, 'Neural Network', 'Neural_Network_CV_Binary_20Epochs_Graph.png', True, 20)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\23FALL\\CS4120_Homework4_Sentiment_Analysis\\sentiment_utils.py:132\u001b[0m, in \u001b[0;36mcreate_training_graph\u001b[1;34m(metrics_fun, train_feats, dev_feats, kind, savepath, verbose, num_epochs)\u001b[0m\n\u001b[0;32m    130\u001b[0m     metrics \u001b[39m=\u001b[39m metrics_fun(x_split_train, y_split_train, X_dev, y_dev, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m    131\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     metrics \u001b[39m=\u001b[39m metrics_fun(num_epochs, x_split_train, y_split_train, X_dev, y_dev, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m    134\u001b[0m \u001b[39m# save y's to appropriate graph y list\u001b[39;00m\n\u001b[0;32m    135\u001b[0m y1\u001b[39m.\u001b[39mappend(metrics[\u001b[39m0\u001b[39m]) \n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\23FALL\\CS4120_Homework4_Sentiment_Analysis\\sentiment_utils.py:212\u001b[0m, in \u001b[0;36mneural_net_metrics\u001b[1;34m(num_epochs, X_train, y_train, X_dev, y_dev, verbose)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39m# make classsification decision based on 0.5 as threshold\u001b[39;00m\n\u001b[0;32m    211\u001b[0m preds \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m y \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m y \u001b[39min\u001b[39;00m preds]\n\u001b[1;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m get_prfa(y_dev, preds, verbose\u001b[39m=\u001b[39;49mverbose)\n\u001b[0;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m get_prfa(y_dev,  preds, verbose\u001b[39m=\u001b[39mverbose)\n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\23FALL\\CS4120_Homework4_Sentiment_Analysis\\sentiment_utils.py:87\u001b[0m, in \u001b[0;36mget_prfa\u001b[1;34m(dev_y, preds, verbose)\u001b[0m\n\u001b[0;32m     85\u001b[0m recall \u001b[39m=\u001b[39m recall_score(dev_y, preds)\n\u001b[0;32m     86\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(dev_y, preds)\n\u001b[1;32m---> 87\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(dev_y, preds)\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m     89\u001b[0m     \u001b[39mprint\u001b[39m(precision, recall, f1, accuracy)\n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:111\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    110\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         unique_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munion1d(y_true, y_pred)\n\u001b[0;32m    112\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    113\u001b[0m         \u001b[39m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[0;32m    114\u001b[0m         \u001b[39m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[0;32m    115\u001b[0m         \u001b[39m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[0;32m    116\u001b[0m         \u001b[39m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[0;32m    117\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    118\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot y_true=\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_true)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe true labels.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:932\u001b[0m, in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_union1d_dispatcher)\n\u001b[0;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munion1d\u001b[39m(ar1, ar2):\n\u001b[0;32m    900\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m    Find the union of two arrays.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39m    array([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 932\u001b[0m     \u001b[39mreturn\u001b[39;00m unique(np\u001b[39m.\u001b[39;49mconcatenate((ar1, ar2), axis\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m))\n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\J-Dog\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create the same graph as with NB and LR, with your neural network model instead!\n",
    "# make sure to re-create your model each time you train it — you don't want to start with\n",
    "# an already trained network!\n",
    "\n",
    "# For a model with one hidden layer of 50 units:\n",
    "# Takes < 15 sec to run on Felix's computer w/ 3 epochs\n",
    "# Takes < 30 sec to run on Felix's computer w/ 10 epochs\n",
    "# Takes < 50 sec to run on Felix's computer w/ 20 epochs\n",
    "# you need not train your model more than 20 epochs\n",
    "# you should experiment with different numbers of epochs to see how performance varies\n",
    "# you need not create an experiment that takes > 10 min to run (please do not do this)\n",
    "\n",
    "# graph for Binary, Count Vectorizer, 5 epochs\n",
    "train_feats = [(x, y) for x,y in zip(X_train_CV_binary, y_train) ]\n",
    "dev_feats = [(x, y) for x,y in zip(X_dev_CV_binary, y_dev) ]\n",
    "sutils.create_training_graph(sutils.neural_net_metrics, train_feats, dev_feats, 'Neural Network', 'Neural_Network_CV_Binary_5Epochs_Graph.png', True, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# graph for Binary, Count Vectorizer, 10 epochs\n",
    "train_feats = [(x, y) for x,y in zip(X_train_CV_binary, y_train) ]\n",
    "dev_feats = [(x, y) for x,y in zip(X_dev_CV_binary, y_dev) ]\n",
    "sutils.create_training_graph(sutils.neural_net_metrics, train_feats, dev_feats, 'Neural Network', 'Neural_Network_CV_Binary_10Epochs_Graph.png', True, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# graph for Binary, Count Vectorizer, 10 epochs\n",
    "train_feats = [(x, y) for x,y in zip(X_train_CV_binary, y_train) ]\n",
    "dev_feats = [(x, y) for x,y in zip(X_dev_CV_binary, y_dev) ]\n",
    "sutils.create_training_graph(sutils.neural_net_metrics, train_feats, dev_feats, 'Neural Network', 'Neural_Network_CV_Binary_20Epochs_Graph.png', True, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get f1 score for Count Vectorizer, binary, 10 epochs\n",
    "sutils.neural_net_metrics(X_train_CV_binary, y_train, X_dev_CV_binary, y_dev, 10)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get f1 score for Count Vectorizer, multinomial, 10 epochs\n",
    "sutils.neural_net_metrics(X_train_CV_binary, y_train, X_dev_CV_binary, y_dev, 10)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the f1 scores for your model with the following settings, using the same number of epochs to train in both cases:\n",
    "- number of epochs used: 10\n",
    "- multinomial features: __YOUR ANSWER HERE__ \n",
    "- binarized features: __YOUR ANSWER HERE__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
