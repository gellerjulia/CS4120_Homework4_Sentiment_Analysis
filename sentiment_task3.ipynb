{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4: Sentiment Analysis - Task 3\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names & Sections\n",
    "----\n",
    "Names: Julia Geller (4120) and Shae Marks (4120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Train a Logistic Regression Model (20 points)\n",
    "----\n",
    "\n",
    "Using `sklearn`'s implementation of `LogisticRegression`, conduct a similar analysis on the performance of a Logistic Regression classifier on the provided data set.\n",
    "\n",
    "Using the `time` module, you'll compare and contrast how long it takes your home-grown BoW vectorizing function vs. `sklearn`'s `CountVectorizer`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shaem\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import time\n",
    "import sentiment_utils as sutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constants for the files we are using\n",
    "TRAIN_FILE = \"movie_reviews_train.txt\"\n",
    "DEV_FILE = \"movie_reviews_dev.txt\"\n",
    "\n",
    "# load in your data and make sure you understand the format\n",
    "# Do not print out too much so as to impede readability of your notebook\n",
    "train_tups = sutils.generate_tuples_from_file(TRAIN_FILE)\n",
    "dev_tups = sutils.generate_tuples_from_file(DEV_FILE)\n",
    "\n",
    "# some variables you may want to use\n",
    "BINARIZED = True\n",
    "# USE_COUNT_VECTORIZER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train and devlopment tuples into X and y\n",
    "X_train = train_tups[0]\n",
    "y_train = train_tups[1]\n",
    "\n",
    "X_dev = dev_tups[0]\n",
    "y_dev = dev_tups[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That took: 6.692219257354736 seconds\n"
     ]
    }
   ],
   "source": [
    "# how much time does it take to featurize the all data with your implementation?\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "vocab = sutils.create_index(X_train)\n",
    "X_train_vects = sutils.featurize('own', vocab, X_train, binary = False, verbose = False)\n",
    "X_dev_vects = sutils.featurize('own', vocab, X_dev, binary = False, verbose = False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"That took:\", end - start, \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaem\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1375: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That took: 1.4688332080841064 seconds\n"
     ]
    }
   ],
   "source": [
    "# how much time does it take to featurize the all data with sklearn's CountVectorizer?\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "vocab = sutils.create_index(X_train)\n",
    "X_train_flat = [' '.join(row) for row in X_train]\n",
    "X_dev_flat = [' '.join(row) for row in X_dev]\n",
    "X_train_CV = sutils.featurize('CV', vocab, X_train_flat, binary = False)\n",
    "X_dev_CV = sutils.featurize('CV', vocab, X_dev_flat, binary = False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"That took:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How big is your vocabulary using your vectorization function(s)? The vocabulary using my vectorization function 30,705 words.\n",
    "2. How big is your vocabulary using the `CountVectorizer`? The vocabulary using my vectorization function 30,705 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average percent of entries that are zero in each vector for my vectorized training data: 0.995092452369321\n",
      "The average percent of entries that are zero in each vector for sklearn vectorized training data: 0.9957819369809477\n"
     ]
    }
   ],
   "source": [
    "#  write any code you need analyze the relative sparsity of your vectorized representations of the data\n",
    "# YOUR CODE HERE\n",
    "def pct_zeros(X):\n",
    "    cnt = [(x.shape[0]-np.count_nonzero(x))/x.shape[0] for x in X]\n",
    "    return sum(cnt)/len(cnt)\n",
    "\n",
    "# Print out the average % of entries that are zeros in each vector in the vectorized training data\n",
    "# YOUR CODE HERE\n",
    "print('The average percent of entries that are zero in each vector for my vectorized training data:', sutils.percent_zeros(X_train_vects))\n",
    "print('The average percent of entries that are zero in each vector for sklearn vectorized training data:', sutils.percent_zeros(X_train_CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the provided dev set, evaluate your model with precision, recall, and f1 score as well as accuracy\n",
    "# You may use nltk's implemented `precision`, `recall`, `f_measure`, and `accuracy` functions\n",
    "# (make sure to look at the documentation for these functions!)\n",
    "# you will be creating a similar graph for logistic regression and neural nets, so make sure\n",
    "# you use functions wisely so that you do not have excessive repeated code\n",
    "# write any helper functions you need in sentiment_utils.py (functions that you'll use in your other notebooks as well)\n",
    "\n",
    "\n",
    "# create a graph of your classifier's performance on the dev set as a function of the amount of training data\n",
    "# the x-axis should be the amount of training data (as a percentage of the total training data)\n",
    "# the y-axis should be the performance of the classifier on the dev set\n",
    "# the graph should have 4 lines, one for each of precision, recall, f1, and accuracy\n",
    "# the graph should have a legend, title, and axis labels\n",
    "\n",
    "# takes approx 30 sec on Felix's computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the following 4 combinations to determine which has the best final f1 score for your Logistic Regression model:\n",
    "- your vectorized features, multinomial: __enter your final f1 score here__\n",
    "- CountVectorizer features, multinomial: __enter your final f1 score here__\n",
    "- your vectorized features, binarized: __enter your final f1 score here__\n",
    "- CountVectorizer features, binarized: __enter your final f1 score here__\n",
    "\n",
    "Produce your graph(s) for the combination with the best final f1 score.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6120 REQUIRED\n",
    "----\n",
    "\n",
    "Find the top 100 most important features to your Logistic Regression classifier when using 100% of the training data. To access the weights of your model, you can access the `model.coef_` attribute. You'll want to use a `StandardScalar` preprocessor. This will help us deal with the fact that we expect counts of certain words to be higher (e.g. stop words).\n",
    "\n",
    "To find the importance of a feature, calculate the absolute value of each weight in the model, then order your features according to the absolute values of these weights. The feature with the heighest absolute value weight has the most importance.\n",
    "\n",
    "Use __your__ (not CountVectorizer) multinomial vectors for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# train a model on the scaled inputs\n",
    "# This takes Felix's computer about 6.5 sec to run\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the top 20 most informative features according to this model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-evalaute your LR model with inputs that have been filtered to only use the top 500 most informative features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same graph as before, but with the filtered inputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
